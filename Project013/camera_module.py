"""
camera_module.py - Pi Camera Module 3 + Dual AI Detection
  1. YOLO (local model) ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ó‡πà‡∏≤‡∏°‡∏∑‡∏≠ ASL ‚Üí ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° Motor (Exclusive)
  2. MediaPipe Hands    ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏´‡∏±‡∏ß‡πÅ‡∏°‡πà‡∏°‡∏∑‡∏≠/‡∏Å‡πâ‡∏≠‡∏¢ ‚Üí ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° Servo (Exclusive)
  3. MediaPipe Face     ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‚Üí ‡∏´‡∏¢‡∏∏‡∏î Motor ‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô

Optimization (Frame Skipping):
  - Face: ‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏∏‡∏Å 5 ‡πÄ‡∏ü‡∏£‡∏°
  - YOLO: ‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏∏‡∏Å 5 ‡πÄ‡∏ü‡∏£‡∏°
  - Hands: ‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏∏‡∏Å 3 ‡πÄ‡∏ü‡∏£‡∏°
"""

import cv2
import numpy as np
import subprocess
import time
import os
import mediapipe as mp_lib
from ultralytics import YOLO
from config import (CAMERA_WIDTH, CAMERA_HEIGHT, FACE_MODEL, FACE_CONFIDENCE,
                    HAND_MAX_NUM, HAND_CONFIDENCE, HAND_TRACKING,
                    YOLO_MODEL_PATH, YOLO_CONFIDENCE, YOLO_IMG_SIZE,
                    SERVO_STEP, SERVO_MIN_ANGLE, SERVO_MAX_ANGLE,
                    GESTURE_INTERVAL, SIGN_SPEED_MAP, SKIP_FACE, SKIP_YOLO, SKIP_HANDS)
import shared_state


# === ‡πÅ‡∏õ‡∏•‡∏á sign class ‡πÄ‡∏õ‡πá‡∏ô action ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ===
SIGN_DISPLAY = {
    "s": "0 (Stop)",
    "o": "0 (Stop)",
    "d": "1 (Low)",
    "x": "1 (Low)",
    "v": "2 (Medium)",
    "w": "3 (High)",
}

ALL_VALID = list(SIGN_SPEED_MAP.keys())


def _count_fingers_detail(hand_landmarks, handedness_label):
    """‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ô‡∏¥‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏ä‡∏π‡∏Ç‡∏∂‡πâ‡∏ô + ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏±‡∏ß‡πÅ‡∏°‡πà‡∏°‡∏∑‡∏≠/‡∏Å‡πâ‡∏≠‡∏¢‡πÅ‡∏¢‡∏Å"""
    lm = hand_landmarks.landmark

    # ‡∏´‡∏±‡∏ß‡πÅ‡∏°‡πà‡∏°‡∏∑‡∏≠ (‡πÅ‡∏Å‡∏ô X)
    thumb_tip = lm[mp_lib.solutions.hands.HandLandmark.THUMB_TIP]
    thumb_ip = lm[mp_lib.solutions.hands.HandLandmark.THUMB_IP]

    if handedness_label == "Right":
        thumb_up = thumb_tip.x < thumb_ip.x
    else:
        thumb_up = thumb_tip.x > thumb_ip.x

    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ
    index_up = lm[mp_lib.solutions.hands.HandLandmark.INDEX_FINGER_TIP].y < \
               lm[mp_lib.solutions.hands.HandLandmark.INDEX_FINGER_PIP].y

    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á
    middle_up = lm[mp_lib.solutions.hands.HandLandmark.MIDDLE_FINGER_TIP].y < \
                lm[mp_lib.solutions.hands.HandLandmark.MIDDLE_FINGER_PIP].y

    # ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á
    ring_up = lm[mp_lib.solutions.hands.HandLandmark.RING_FINGER_TIP].y < \
              lm[mp_lib.solutions.hands.HandLandmark.RING_FINGER_PIP].y

    # ‡∏Å‡πâ‡∏≠‡∏¢
    pinky_up = lm[mp_lib.solutions.hands.HandLandmark.PINKY_TIP].y < \
               lm[mp_lib.solutions.hands.HandLandmark.PINKY_PIP].y

    total = sum([thumb_up, index_up, middle_up, ring_up, pinky_up])

    return {
        "total": total,
        "thumb": thumb_up,
        "index": index_up,
        "middle": middle_up,
        "ring": ring_up,
        "pinky": pinky_up,
    }


def camera_worker():
    """Thread (Main): Dual AI Detection - YOLO + MediaPipe"""

    # === MediaPipe Face Detection ===
    mp_face = mp_lib.solutions.face_detection
    mp_draw = mp_lib.solutions.drawing_utils
    face_detection = mp_face.FaceDetection(
        model_selection=FACE_MODEL,
        min_detection_confidence=FACE_CONFIDENCE
    )

    # === MediaPipe Hands ===
    mp_hands = mp_lib.solutions.hands
    hands = mp_hands.Hands(
        max_num_hands=HAND_MAX_NUM,
        min_detection_confidence=HAND_CONFIDENCE,
        min_tracking_confidence=HAND_TRACKING
    )

    # === ‡πÇ‡∏´‡∏•‡∏î YOLO Model (local) ===
    script_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(script_dir, YOLO_MODEL_PATH)

    print(f"[Camera] ‡πÇ‡∏´‡∏•‡∏î YOLO model: {model_path}")
    yolo_model = YOLO(model_path)
    print(f"[Camera] YOLO loaded! Classes: {yolo_model.names}")

    # === ‡πÄ‡∏õ‡∏¥‡∏î Pi Camera ===
    print("[Camera] ‡πÄ‡∏õ‡∏¥‡∏î Pi Camera Module 3 (rpicam-vid)...")

    cmd = [
        'rpicam-vid', '-t', '0',
        '--width', str(CAMERA_WIDTH), '--height', str(CAMERA_HEIGHT),
        '--codec', 'yuv420', '--framerate', '30', '-n', '-o', '-'
    ]

    try:
        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)
    except FileNotFoundError:
        print("[Camera] ‡πÑ‡∏°‡πà‡∏û‡∏ö rpicam-vid!")
        shared_state.stop_event.set()
        return
    except Exception as e:
        print(f"[Camera] ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
        shared_state.stop_event.set()
        return

    yuv_frame_size = CAMERA_WIDTH * CAMERA_HEIGHT * 3 // 2

    print("[Camera] Dual AI Optimization Mode (Skipping Frames)")
    print(f"  - Face Check: ‡∏ó‡∏∏‡∏Å {SKIP_FACE} frames")
    print(f"  - YOLO Check: ‡∏ó‡∏∏‡∏Å {SKIP_YOLO} frames")
    print(f"  - Hands Check: ‡∏ó‡∏∏‡∏Å {SKIP_HANDS} frames")

    last_jog_time = 0
    fps_time = time.time()
    fps_counter = 0
    current_fps = 0
    
    # Frame Counters
    frame_cnt_face = 0
    frame_cnt_yolo = 0
    frame_cnt_hands = 0

    # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ detection (‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏ü‡∏£‡∏°)
    yolo_sign = None
    yolo_conf = 0
    yolo_box_coords = None  # ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á box ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î

    mp_fingers = -1          # -1 = ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏°‡∏∑‡∏≠
    mp_detail = None         # finger detail dict
    mp_landmarks = None      # ‡πÄ‡∏Å‡πá‡∏ö landmarks ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏î
    
    has_face = False
    face_detections = None   # ‡πÄ‡∏Å‡πá‡∏ö face detection ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î

    detection_mode = "NONE"  # YOLO / MP SERVO / NONE
    action_label = "NO HAND"
    servo_label = ""         # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OSD

    try:
        while not shared_state.stop_event.is_set():
            raw_data = proc.stdout.read(yuv_frame_size)
            if len(raw_data) != yuv_frame_size:
                break

            yuv_frame = np.frombuffer(raw_data, dtype=np.uint8).reshape(
                (CAMERA_HEIGHT * 3 // 2, CAMERA_WIDTH)
            )
            frame = cv2.cvtColor(yuv_frame, cv2.COLOR_YUV2BGR_I420)
            frame = cv2.flip(frame, 1)  # ‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á (Mirror)
            rgb_frame = cv2.cvtColor(yuv_frame, cv2.COLOR_YUV2RGB_I420)

            # === FPS ===
            fps_counter += 1
            elapsed = time.time() - fps_time
            if elapsed >= 1.0:
                current_fps = fps_counter / elapsed
                fps_counter = 0
                fps_time = time.time()

            # ==========================================
            # 1. Face Detection (Every SKIP_FACE frames)
            # ==========================================
            frame_cnt_face += 1
            if frame_cnt_face >= SKIP_FACE:
                frame_cnt_face = 0
                face_results = face_detection.process(rgb_frame)
                
                has_face = False
                face_detections = None
                
                if face_results.detections:
                    has_face = True
                    face_detections = face_results.detections
                    shared_state.face_detected.set()
                else:
                    shared_state.face_detected.clear()
            
            # ‡∏ß‡∏≤‡∏î Face (‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
            if face_detections:
                for det in face_detections:
                    mp_draw.draw_detection(frame, det)


            # ==========================================
            # 2. YOLO Sign Language (Every SKIP_YOLO frames)
            # ==========================================
            frame_cnt_yolo += 1
            if frame_cnt_yolo >= SKIP_YOLO:
                frame_cnt_yolo = 0
                
                # Reset ‡∏Ñ‡πà‡∏≤‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô detect ‡πÉ‡∏´‡∏°‡πà
                yolo_sign = None
                yolo_conf = 0
                yolo_box_coords = None

                yolo_results = yolo_model(frame, imgsz=YOLO_IMG_SIZE,
                                          conf=YOLO_CONFIDENCE, verbose=False)

                if yolo_results and len(yolo_results[0].boxes) > 0:
                    for box in yolo_results[0].boxes:
                        cls_id = int(box.cls[0])
                        cls_name = yolo_model.names[cls_id].lower()
                        conf = float(box.conf[0])
                        
                        if cls_name in ALL_VALID and conf > yolo_conf:
                            yolo_sign = cls_name
                            yolo_conf = conf
                            x1, y1, x2, y2 = map(int, box.xyxy[0])
                            yolo_box_coords = (x1, y1, x2, y2)
            
            # ‡∏ß‡∏≤‡∏î YOLO Box (‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
            if yolo_box_coords and yolo_sign:
                x1, y1, x2, y2 = yolo_box_coords
                
                # ‡πÉ‡∏ä‡πâ SIGN_DISPLAY ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (d=1, s=0 ‡∏Ø‡∏•‡∏Ø)
                display_text = SIGN_DISPLAY.get(yolo_sign, yolo_sign.upper())
                # ‡∏ï‡∏±‡∏î‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤ "0", "1" ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏ï‡πá‡∏°‡πÜ "0 (Stop)" ‡∏Å‡πá‡πÑ‡∏î‡πâ
                # ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡πÇ‡∏ä‡∏ß‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà config ‡πÑ‡∏ß‡πâ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏™‡∏ß‡∏¢‡∏Å‡∏ß‡πà‡∏≤
                
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f"YOLO:{display_text}",
                            (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)


            # ==========================================
            # 3. MediaPipe Hands (Every SKIP_HANDS frames)
            # ==========================================
            frame_cnt_hands += 1
            if frame_cnt_hands >= SKIP_HANDS:
                frame_cnt_hands = 0
                servo_label = ""
                
                mp_fingers = -1
                mp_detail = None
                mp_landmarks = None

                hand_results = hands.process(rgb_frame)

                if hand_results.multi_hand_landmarks:
                    # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà‡∏°‡∏∑‡∏≠‡πÅ‡∏£‡∏Å
                    hlm = hand_results.multi_hand_landmarks[0]
                    mp_landmarks = hlm
                    
                    label = hand_results.multi_handedness[0].classification[0].label
                    mp_detail = _count_fingers_detail(hlm, label)
                    mp_fingers = mp_detail["total"]

            # ‡∏ß‡∏≤‡∏î Hands (‡πÉ‡∏ä‡πâ‡∏ú‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î) -- ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠ *‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠* YOLO Sign
            if mp_landmarks and not yolo_sign:
                mp_lib.solutions.drawing_utils.draw_landmarks(
                    frame, mp_landmarks, mp_hands.HAND_CONNECTIONS,
                    mp_lib.solutions.drawing_styles.get_default_hand_landmarks_style(),
                    mp_lib.solutions.drawing_styles.get_default_hand_connections_style()
                )


            # ==========================================
            # Logic & Control (Update every frame based on latest state)
            # ==========================================
            
            # --- Servo Control Logic (MediaPipe Only) ---
            servo_action = None  # "right" or "left" or None

            if mp_detail:
                thumb = mp_detail["thumb"]
                index = mp_detail["index"]
                middle = mp_detail["middle"]
                ring = mp_detail["ring"]
                pinky = mp_detail["pinky"]

                # üëç ‡∏´‡∏±‡∏ß‡πÅ‡∏°‡πà‡∏°‡∏∑‡∏≠‡∏ä‡∏π‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏≠‡∏∑‡πà‡∏ô‡∏á‡∏≠‡∏´‡∏°‡∏î)
                if thumb and not index and not middle and not ring and not pinky:
                    servo_action = "right"
                    servo_label = "SERVO: üëç Thumb +5¬∞"

                # ü§ô ‡∏Å‡πâ‡∏≠‡∏¢‡∏ä‡∏π‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏≠‡∏∑‡πà‡∏ô‡∏á‡∏≠‡∏´‡∏°‡∏î)
                elif pinky and not thumb and not index and not middle and not ring:
                    servo_action = "left"
                    servo_label = "SERVO: ü§ô Pinky -5¬∞"
                else:
                    servo_label = "" # Clear label if hand is present but not servo gesture

            # ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ Servo (check timer)
            if servo_action:
                now = time.time()
                if now - last_jog_time >= GESTURE_INTERVAL:
                    status = shared_state.get_status()
                    current_target = status["target_servo_angle"]

                    if servo_action == "right":
                        new_angle = min(current_target + SERVO_STEP, SERVO_MAX_ANGLE)
                        shared_state.set_target_servo_angle(new_angle)
                        last_jog_time = now
                    elif servo_action == "left":
                        new_angle = max(current_target - SERVO_STEP, SERVO_MIN_ANGLE)
                        shared_state.set_target_servo_angle(new_angle)
                        last_jog_time = now


            # --- Motor Logic (YOLO Only - No Cross Check) ---
            final_speed = None

            if yolo_sign and not servo_action:
                detection_mode = "YOLO"
                if yolo_sign in SIGN_SPEED_MAP:
                    final_speed = SIGN_SPEED_MAP[yolo_sign]
            
            elif servo_action:
                detection_mode = "MP SERVO"

            else:
                detection_mode = "NONE"


            # --- ‡∏™‡∏£‡πâ‡∏≤‡∏á action label ---
            parts = []
            if yolo_sign:
                parts.append(f"YOLO:{yolo_sign.upper()}")
            
            if parts:
                action_label = f"{' + '.join(parts)} [{detection_mode}]"
            else:
                action_label = "NO HAND"


            # --- ‡∏™‡∏±‡πà‡∏á‡∏á‡∏≤‡∏ô Motor Shared State ---
            if final_speed is not None:
                if has_face:
                    shared_state.set_target_speed(0.0)
                    shared_state.set_finger_count(0)
                else:
                    shared_state.set_target_speed(final_speed)
                    # Translate YOLO sign to arbitrary finger count for display if needed, 
                    # but here we just pass 0 or maybe mapped number for UI consisteny
                    # (optional: mapping logic kept simple)
                    finger_map = {"0":0,"0":0,"1":1,"1":1,"2":2,"3":3}
                    shared_state.set_finger_count(finger_map.get(yolo_sign, 0))


            # ==========================================
            # OSD Display
            # ==========================================
            status = shared_state.get_status()
            m = status["motor_speed"]
            s = status["servo_angle"]

            # Motor
            if has_face:
                motor_color = (0, 0, 255)
                motor_text = "MOTOR: 0% (FACE!)"
            else:
                if m == 0:   motor_color = (128, 128, 128)
                elif m <= 30: motor_color = (0, 255, 255)
                elif m <= 60: motor_color = (0, 165, 255)
                else:         motor_color = (0, 0, 255)
                motor_text = f"MOTOR: {m}%"

            cv2.putText(frame, motor_text, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, motor_color, 2)

            # Servo
            cv2.putText(frame, f"Servo: {s} deg", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            # Servo action (thumb/pinky)
            if servo_label:
                cv2.putText(frame, servo_label, (10, CAMERA_HEIGHT - 20),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 165, 0), 2)

            # Face
            face_color = (0, 0, 255) if has_face else (0, 255, 0)
            face_text = "FACE: DETECTED" if has_face else "FACE: NONE"
            cv2.putText(frame, face_text, (10, 90),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, face_color, 2)

            # AI Result
            if "YOLO" in detection_mode:
                ai_color = (0, 255, 0)       # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß
            elif "MP" in detection_mode:
                ai_color = (255, 165, 0)     # ‡∏™‡πâ‡∏°
            else:
                ai_color = (128, 128, 128)   # ‡πÄ‡∏ó‡∏≤

            cv2.putText(frame, f"AI: {action_label}", (10, 120),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.55, ai_color, 2)

            # FPS
            cv2.putText(frame, f"FPS: {current_fps:.1f}", (10, 150),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)

            # Progress bar Motor
            bar_width = int((m / 100) * 200)
            cv2.rectangle(frame, (10, 160), (210, 180), (50, 50, 50), -1)
            cv2.rectangle(frame, (10, 160), (10 + bar_width, 180), motor_color, -1)

            cv2.imshow('Smart Fan - Dual AI (No Cross-Check)', frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                shared_state.stop_event.set()
                break

    except Exception as e:
        print(f"[Camera] Error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        face_detection.close()
        hands.close()
        proc.terminate()
        proc.wait()
        cv2.destroyAllWindows()
        print("[Camera] ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á")
