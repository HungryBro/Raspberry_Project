# 🤖 Smart AI Fan — Raspberry Pi 5 Hand Gesture Control

> ระบบพัดลมอัจฉริยะที่ควบคุมด้วย **AI ตรวจจับท่ามือ** รันบน Raspberry Pi 5
> พัฒนาแบบ Progressive — จาก MediaPipe → YOLO → Dual AI

---

## 📋 สารบัญ

- [ภาพรวมโปรเจค](#ภาพรวมโปรเจค)
- [สถาปัตยกรรมระบบ](#สถาปัตยกรรมระบบ)
- [Project010 — MediaPipe](#project010--mediapipe-hand-gesture)
- [Project011 — YOLO Cloud API](#project011--yolo-cloud-api-sign-language)
- [Project012 — YOLO Local Model](#project012--yolo-local-model-self-trained)
- [Project013 — Dual AI](#project013--dual-ai-yolo--mediapipe)
- [ฮาร์ดแวร์](#ฮาร์ดแวร์)
- [วิธีติดตั้งและใช้งาน](#วิธีติดตั้งและใช้งาน)

---

## ภาพรวมโปรเจค

| Project | AI Engine | ความยาก | Internet |
|---------|-----------|---------|----------|
| **010** | MediaPipe Hands | 🟡 กลาง | ไม่ต้อง |
| **011** | YOLO (Roboflow Cloud API) | 🟠 ยาก | **ต้อง** |
| **012** | YOLO (Local Model, train เอง) | 🟠 ยาก+ | ไม่ต้อง |
| **013** | YOLO + MediaPipe (Independent Role) | 🔴 ยากสุด | ไม่ต้อง |

### ฟีเจอร์ที่ทุก Project มีเหมือนกัน
- ✅ ควบคุม **Motor** (พัดลม) ด้วยท่ามือ — ปรับความเร็วได้ 4 ระดับ (0%, 30%, 60%, 100%)
- ✅ ควบคุม **Servo** ด้วยท่ามือ — หมุนซ้าย/ขวา ครั้งละ 5°
- ✅ **Face Detection** — ตรวจจับใบหน้า → **หยุด Motor ฉุกเฉิน** (ป้องกันอันตราย)
- ✅ **OSD** (On-Screen Display) — แสดงสถานะแบบ Real-time บนหน้าจอ
- ✅ **Multi-threading** — Camera, Motor, Servo ทำงานแยก Thread

---

## สถาปัตยกรรมระบบ

### โครงสร้างร่วม (ทุก Project)

```
┌──────────────────────────────────────────────────┐
│                     main.py                       │
│               (Thread Manager)                    │
│                                                   │
│    ┌─────────┐   ┌─────────┐   ┌──────────────┐ │
│    │  Motor  │   │  Servo  │   │   Camera     │ │
│    │ Thread  │   │ Thread  │   │ (Main Thread)│ │
│    └────┬────┘   └────┬────┘   └──────┬───────┘ │
│         │             │               │          │
│         └─────────────┴───────────────┘          │
│                       │                           │
│              shared_state.py                      │
│          (Thread-safe variables)                  │
│          ┌──────────────────────┐                 │
│          │ target_speed         │                 │
│          │ target_servo_angle   │                 │
│          │ face_detected (Event)│                 │
│          │ stop_event (Event)   │                 │
│          └──────────────────────┘                 │
└──────────────────────────────────────────────────┘

ฮาร์ดแวร์:
  Pi Camera 3 ──(rpicam-vid)──→ YUV420 pipe ──→ OpenCV
  GPIO 12 (PWM) ──→ TB6612 Motor Driver ──→ DC Motor (พัดลม)
  GPIO 17, 27    ──→ TB6612 AIN1/AIN2 (ทิศทาง)
  GPIO 19 (PWM) ──→ Servo MG996R (หมุนหัวพัดลม)
```

### Pipeline การประมวลผลภาพ

```
rpicam-vid (30fps)
    │
    ▼
YUV420 raw data (stdout pipe)
    │
    ▼
numpy reshape → YUV frame
    │
    ├──→ cvtColor(YUV2BGR) → OpenCV frame (แสดงผล + YOLO)
    │
    └──→ cvtColor(YUV2RGB) → RGB frame (MediaPipe)
            │
            ├──→ Face Detection
            ├──→ Hand Detection (010, 013)
            └──→ YOLO Inference (011, 012, 013)
```

---

## Project010 — MediaPipe Hand Gesture

### หลักการทำงาน

ใช้ **Google MediaPipe** ตรวจจับมือและนับนิ้ว จาก **Hand Landmark 21 จุด**

### อัลกอริทึม: MediaPipe Hands

MediaPipe Hands ทำงาน 2 ขั้นตอน:

```
ขั้นที่ 1: Palm Detection (BlazePalm)
  - ใช้ SSD (Single Shot Detector) ค้นหาฝ่ามือในภาพ
  - ได้ bounding box ของฝ่ามือ

ขั้นที่ 2: Hand Landmark Model
  - ใช้ Regression Network หาพิกัด 21 จุด (x, y, z)
  - จุดสำคัญ: ข้อมือ(0), ปลายนิ้ว(4,8,12,16,20), ข้อนิ้ว(PIP/IP)
```

```
        8   12  16  20
        │   │   │   │
    4   7   11  15  19
    │   │   │   │   │
    3   6   10  14  18
    │   │   │   │   │
    2   5   9   13  17
     \  │   │   │  /
      \ │   │  │/
        0 (ข้อมือ)

    จุด 4  = ปลายหัวแม่มือ (THUMB_TIP)
    จุด 8  = ปลายนิ้วชี้ (INDEX_FINGER_TIP)
    จุด 12 = ปลายนิ้วกลาง (MIDDLE_FINGER_TIP)
    จุด 16 = ปลายนิ้วนาง (RING_FINGER_TIP)
    จุด 20 = ปลายก้อย (PINKY_TIP)
```

### อัลกอริทึม: การนับนิ้ว (`_count_fingers`)

```python
# หลักการ: เปรียบเทียบตำแหน่ง Y ของปลายนิ้ว (TIP) กับข้อนิ้ว (PIP)
# ถ้า TIP.y < PIP.y → นิ้วชูขึ้น (แกน Y กลับหัว: 0 = บน)

สำหรับ 4 นิ้ว (ชี้, กลาง, นาง, ก้อย):
    if TIP.y < PIP.y:
        count += 1    # นิ้วชูขึ้น

สำหรับ หัวแม่มือ (ใช้แกน X):
    if มือขวา: thumb_tip.x < thumb_ip.x → ชูออก
    if มือซ้าย: thumb_tip.x > thumb_ip.x → ชูออก
```

### Mapping: นิ้ว → การควบคุม

| นิ้วที่ชู | ความเร็ว Motor | Servo |
|-----------|---------------|-------|
| 0 (กำปั้น) | 0% (หยุด) | — |
| 1 (ชี้) | 30% | — |
| 2 (ชี้+กลาง) | 60% | — |
| 3 (ชี้+กลาง+นาง) | 100% | — |
| 4 นิ้วก้อย | — | +5° (หมุนขวา) |
| 5 นิ้วโป้ง | — | -5° (หมุนซ้าย) |

### โครงสร้างไฟล์

```
Project010/
├── config.py            # ค่าคงที่ทั้งหมด (GPIO pins, thresholds)
├── camera_module.py     # MediaPipe Hands + Face Detection + OSD
├── main.py              # Thread Manager
├── shared_state.py      # Thread-safe shared variables
├── motor_module.py      # PWM Motor control (TB6612)
├── servo_module.py      # Servo MG996R control
└── requirements.txt     # Dependencies
```

---

## Project011 — YOLO Cloud API (Sign Language)

### หลักการทำงาน

ใช้ **Roboflow Cloud API** เรียก model **extrdb/2** ที่ train ไว้บน Roboflow
ตรวจจับ **ท่ามือภาษามือ ASL** (American Sign Language) แล้ว map เป็นคำสั่งพัดลม

### อัลกอริทึม: Roboflow Inference API

```
frame จากกล้อง
    │
    ▼
inference_sdk.InferenceHTTPClient
    │
    ▼
ส่งภาพไป Roboflow Cloud API (HTTPS)
    │
    ▼
Roboflow 3.0 Object Detection (Fast) + COCO Checkpoint
    │
    ▼
ผลลัพธ์ JSON: predictions[{class, confidence, x, y, width, height}]
    │
    ▼
เลือก prediction ที่ confidence สูงสุด + อยู่ใน class ที่กำหนด
```

### Model: extrdb/2

| รายละเอียด | ค่า |
|-----------|-----|
| Dataset | extrdb v2 (8,100 ภาพ) |
| Classes | 27 (a-z + 0) — ภาษามือ ASL |
| Model Type | Roboflow 3.0 Object Detection (Fast) |
| Checkpoint | COCO |
| mAP@50 | 98.5% |
| Precision | 98.3% |
| Recall | 96.5% |

### Mapping: ท่ามือ ASL → การควบคุม

| ท่ามือ | ตัวอักษร ASL | ลักษณะมือ | ผลลัพธ์ |
|--------|-------------|----------|---------|
| ✊ | S | กำปั้น | Motor 0% |
| 👌 | O | วงกลม | Motor 0% |
| ☝️ | D | ชี้ 1 นิ้ว | Motor 30% |
| 🤞 | X | งอนิ้วชี้ | Motor 30% |
| ✌️ | V | ชู 2 นิ้ว | Motor 60% |
| 🤟 | W | ชู 3 นิ้ว | Motor 100% |
| 👍 | T | กำ+หัวแม่มือ | Servo +5° |
| 🤙 | Y | ชากา | Servo -5° |

### Face Detection

ยังคงใช้ **MediaPipe Face Detection** สำหรับตรวจจับใบหน้า (ไม่ได้ใช้ YOLO)

### โครงสร้างไฟล์

```
Project011/
├── config.py            # Roboflow API Key + Model ID + Mapping
├── camera_module.py     # Roboflow inference_sdk + MediaPipe Face
├── main.py
├── shared_state.py
├── motor_module.py
├── servo_module.py
└── requirements.txt     # inference (Roboflow SDK)
```

### ข้อจำกัด
- ⚠️ **ต้องต่อ Internet** ตลอดเวลา (ส่งภาพไป Cloud)
- ⚠️ **มี Latency** ~0.3-1 วินาทีต่อ frame (ขึ้นกับเน็ต)

---

## Project012 — YOLO Local Model (Self-Trained)

### หลักการทำงาน

ใช้ **YOLOv11 Nano** ที่ **train เอง** จาก dataset extrdb v2 (8,100 ภาพ)
รัน inference **บน Pi โดยตรง** ไม่ต้องต่อ internet

### อัลกอริทึม: YOLOv11 (You Only Look Once)

```
                    Input Image (640×640)
                          │
                ┌─────────▼─────────┐
                │    Backbone       │
                │  (Feature         │
                │   Extraction)     │
                │  CSPDarknet +     │
                │  C3k2 blocks      │
                └─────────┬─────────┘
                          │
                ┌─────────▼─────────┐
                │      Neck         │
                │  (Feature         │
                │   Fusion)         │
                │  FPN + PAN        │
                │  (multi-scale)    │
                └─────────┬─────────┘
                          │
                ┌─────────▼─────────┐
                │      Head         │
                │  (Detection)      │
                │  - Bounding Box   │
                │  - Class Score    │
                │  - Confidence     │
                └─────────┬─────────┘
                          │
                ┌─────────▼─────────┐
                │  Post-Processing  │
                │  - NMS            │
                │  - Confidence     │
                │    threshold      │
                └───────────────────┘
```

**YOLO ทำงานต่างจาก MediaPipe:**
- MediaPipe = ตรวจจับมือ → หา 21 landmarks → นับนิ้วด้วย logic
- YOLO = **ดูภาพรวม → จำแนก class โดยตรง** (ไม่ต้องนับนิ้วเอง)

### การ Train Model

```
Dataset:     extrdb v2 (8,100 ภาพ, 27 classes)
Base Model:  yolo11n.pt (YOLOv11 Nano, pretrained บน COCO)
Image Size:  640×640
Epochs:      100 (early stopping patience=15)
Batch Size:  16
GPU:         NVIDIA GeForce RTX 4050 Laptop
Augment:     เปิด (flip, rotate, mosaic, mixup)
Workers:     0 (ป้องกัน Windows multiprocessing error)
```

### ผลการ Train

| Metric | ค่า |
|--------|-----|
| **mAP@50** | **98.3%** |
| **Precision** | **97.1%** |
| **Recall** | **96.7%** |
| mAP@50-95 | 90.0% |
| Inference Speed | 16.6ms/image |

### Mapping

เหมือนกับ Project011 ทุกประการ (S,O→0%, D,X→30%, V→60%, W→100%, T→Servo+, Y→Servo-)

### โครงสร้างไฟล์

```
Project012/
├── models/
│   └── best.pt          # YOLO model ที่ train เอง (5.5 MB)
├── config.py            # YOLO local path + Mapping
├── camera_module.py     # ultralytics YOLO + MediaPipe Face
├── main.py
├── shared_state.py
├── motor_module.py
├── servo_module.py
└── requirements.txt     # ultralytics
```

### ข้อดีเทียบกับ Project011
- ✅ **ไม่ต้องต่อ Internet**
- ✅ **เร็วกว่ามาก** (inference local ~17ms vs cloud ~300-1000ms)
- ✅ **อาจารย์ประทับใจ** — train model เองจาก dataset

---

## Project013 — Dual AI (YOLO + MediaPipe)

### หลักการทำงาน

ใช้ **AI 3 ตัวพร้อมกัน** แบ่งหน้าที่ชัดเจน:
1. **YOLO** (local model) → ตรวจจับท่ามือ ASL → **ควบคุม Motor** (Speed)
2. **MediaPipe Hands** → ตรวจจับนิ้ว (หัวแม่มือ/ก้อย) → **ควบคุม Servo** (Angle)
3. **MediaPipe Face** → ตรวจจับใบหน้า → **หยุด Motor ฉุกเฉิน** (Safety)

### AI แต่ละตัวรับผิดชอบอะไร?

```
┌───────────────────────────────────────────────────────────────┐
│                    ภาพจากกล้อง (1 frame)                       │
│                                                                │
│    ┌────────────────────┐        ┌─────────────────────────┐  │
│    │  🤖 YOLO (Motor)    │        │  🖐️ MediaPipe (Servo)   │  │
│    │  → ควบคุม Motor     │        │  → ควบคุม Servo         │  │
│    │                     │        │                         │  │
│    │ วิเคราะห์:          │        │ วิเคราะห์:               │  │
│    │ - จำแนกท่าทาง ASL   │        │ - ตรวจหา Thumb/Pinky    │  │
│    │ - กำหนดความเร็ว     │        │ - คำนวณมุม Servo        │  │
│    │                     │        │                         │  │
│    │ Output:             │        │ Output:                  │  │
│    │ class="v" → Motor   │        │ thumb=✅ → Servo +5°     │  │
│    └────────┬────────────┘        └──────────┬───────────────┘  │
│             │                                │                  │
│             └───────────┬────────────────────┘                  │
│                         ▼                                       │
│              Action (Independent Roles)                          │
└───────────────────────────────────────────────────────────────┘
```

**สรุป: YOLO vs MediaPipe ทำอะไรต่างกัน?**

| | 🤖 **YOLO** → Motor | 🖐️ **MediaPipe** → Servo |
|---|---|---|
| **หน้าที่** | ควบคุม **ความเร็ว Motor** | ควบคุม **มุม Servo** |
| **วิธีวิเคราะห์** | จำแนกท่าทาง ASL (Global) | ตรวจจับนิ้วนิ้ว (Local) |
| **รู้ว่านิ้วไหนชู?** | ❌ ไม่รู้ (จำ Pattern) | ✅ รู้ (Finger State) |
| **ความแม่น** | สูงมาก (98.3%) | ยืดหยุ่นตามระยะ |
| **ต้อง train?** | ✅ ต้อง (8100 ภาพ) | ❌ ใช้ได้เลย (Pretrained) |

---

### 🤚 ท่ามือควบคุม Motor (YOLO ตรวจจับ)

YOLO ดูภาพรวมทั้งมือแล้ว **จำแนก class** โดยตรง ไม่ต้องนับนิ้วเอง

#### ท่าที่ 1: ✊ S (กำปั้น) → Motor 0% (หยุด)

```
ลักษณะมือ: กำมือทั้งหมด หัวแม่มือทับหน้านิ้วที่เหลือ

    🤖 YOLO เห็น:  class="s"  (จำรูปแบบกำปั้น ASL)
    🖐️ Action: Motor 0% (Stop)
```

#### ท่าที่ 2: 👌 O (วงกลม) → Motor 0% (หยุด)

```
ลักษณะมือ: หัวแม่มือจรดนิ้วชี้เป็นวงกลม "O"

    🤖 YOLO เห็น:  class="o"  (จำรูปวงกลม ASL)
    🖐️ Action: Motor 0% (Stop)
```

#### ท่าที่ 3: ☝️ D (ชี้ 1 นิ้ว) → Motor 30%

```
ลักษณะมือ: ชูนิ้วชี้ตรงขึ้น นิ้วอื่นงอ

         8 ← นิ้วชี้ชูขึ้น ✅
         │
         7
         │
    4    6
    │    │
    3    5
    │    │
    2    │   งอ  งอ  งอ
     \   │   │   │   │
      \  │   │   │  /
        0

    🤖 YOLO เห็น:  class="d"  (จำรูป D ของ ASL)
    🖐️ Action: Motor 30% (Low)
```

#### ท่าที่ 4: 🤞 X (งอนิ้วชี้) → Motor 30%

```
ลักษณะมือ: ชูนิ้วชี้แล้วงอข้อบน (เหมือนตะขอ)

    🤖 YOLO เห็น:  class="x"  (จำรูป X ของ ASL)
    🖐️ Action: Motor 30% (Low)
```

#### ท่าที่ 5: ✌️ V (ชู 2 นิ้ว) → Motor 60%

```
ลักษณะมือ: ชูนิ้วชี้ + นิ้วกลาง แยกออก (V sign)

         8   12 ← นิ้วชี้ + กลาง ชูขึ้น ✅✅
         │   │
         7   11
         │   │
    4    6   10
    │    │   │
    3    5   9   งอ  งอ
    │    │   │   │   │
    2    │   │   │  /
     \   │   │  │/
        0

    🤖 YOLO เห็น:  class="v"  (จำรูป V ของ ASL)
    🖐️ Action: Motor 60% (Medium)
```

#### ท่าที่ 6: 🤟 W (ชู 3 นิ้ว) → Motor 100%

```
ลักษณะมือ: ชูนิ้วชี้ + กลาง + นาง (W sign)

         8   12  16 ← ชี้ + กลาง + นาง ✅✅✅
         │   │   │
         7   11  15
         │   │   │
    4    6   10  14
    │    │   │   │
    3    5   9   13  งอ
    │    │   │   │   │
    2    │   │   │  /
     \   │   │  │/
        0

    🤖 YOLO เห็น:  class="w"  (จำรูป W ของ ASL)
    🖐️ Action: Motor 100% (High)
```

---

### 🔄 ท่ามือควบคุม Servo (MediaPipe ตรวจจับ)

Servo ใช้ **MediaPipe Hands** ตรวจจับว่า **นิ้วไหนชู** โดยตรง
ไม่ได้ใช้ YOLO เพราะ MediaPipe รู้ตำแหน่งนิ้วแต่ละนิ้วแม่นยำกว่า

#### ท่าที่ 7: 👍 หัวแม่มือ (อย่างเดียว) → Servo +5° (หมุนขวา)

```
ลักษณะมือ: ชูหัวแม่มือขึ้น นิ้วอื่นกำหมด (thumbs up)

    4 ← หัวแม่มือ ชู ✅
    │
    3
    │
    2     งอ  งอ  งอ  งอ
    │     │   │   │   │
    │     │   │   │   │
     \    │   │   │  /
      \   │   │  │/
        0

    🖐️ MP วิเคราะห์แต่ละนิ้ว:
    หัวแม่มือ:  TIP.x ชูออก → ✅ ชู
    นิ้วชี้:    TIP.y > PIP.y → ❌ งอ
    นิ้วกลาง:  TIP.y > PIP.y → ❌ งอ
    นิ้วนาง:   TIP.y > PIP.y → ❌ งอ
    ก้อย:      TIP.y > PIP.y → ❌ งอ
    ────────────────────────────
    เงื่อนไข: thumb=✅ AND นิ้วอื่นทั้งหมด=❌
    → ✅ Servo +5° (หมุนขวา)

    ⚠️ ไม่ใช้ YOLO เพราะ MediaPipe ตรวจได้ตรงๆ
       ว่าเป็นหัวแม่มือชูอย่างเดียว
```

#### ท่าที่ 8: 🤙 ก้อย (อย่างเดียว) → Servo -5° (หมุนซ้าย)

```
ลักษณะมือ: ชูก้อยขึ้น นิ้วอื่นกำหมด (pinky up)

                              20 ← ก้อย ชู ✅
                              │
    งอ   งอ  งอ  งอ          19
     │    │   │   │           │
     │    │   │   │           18
     │    │   │   │          /
      \   │   │   │        /
       \  │   │  │/
        0

    🖐️ MP วิเคราะห์แต่ละนิ้ว:
    หัวแม่มือ:  ❌ งอ
    นิ้วชี้:    TIP.y > PIP.y → ❌ งอ
    นิ้วกลาง:  TIP.y > PIP.y → ❌ งอ
    นิ้วนาง:   TIP.y > PIP.y → ❌ งอ
    ก้อย:      TIP.y < PIP.y → ✅ ชู
    ────────────────────────────
    เงื่อนไข: pinky=✅ AND นิ้วอื่นทั้งหมด=❌
    → ✅ Servo -5° (หมุนซ้าย)
```

---

### สรุป: แต่ละท่าใช้ AI ตัวไหนตัดสิน? (อิสระต่อกัน)

| ท่ามือ | รับผิดชอบโดย | หน้าที่ | วิธีการตัดสิน | ผลลัพธ์ |
|--------|-------------|---------|---------------|---------|
| ✊ ASL 'S' | 🤖 YOLO | Motor | Pattern Recognition | Motor 0% |
| 👌 ASL 'O' | 🤖 YOLO | Motor | Pattern Recognition | Motor 0% |
| ☝️ ASL 'D' | 🤖 YOLO | Motor | Pattern Recognition | Motor 30% |
| 🤞 ASL 'X' | 🤖 YOLO | Motor | Pattern Recognition | Motor 30% |
| ✌️ ASL 'V' | 🤖 YOLO | Motor | Pattern Recognition | Motor 60% |
| 🤟 ASL 'W' | 🤖 YOLO | Motor | Pattern Recognition | Motor 100% |
| 👍 Thumb Up | 🖐️ MediaPipe | Servo | Thumb extension | Servo +5° |
| 🤙 Pinky Up | 🖐️ MediaPipe | Servo | Pinky extension | Servo -5° |

> **หมายเหตุ:** ใน Project 013 แยกหน้าที่กันเด็ดขาด YOLO ไม่ยุ่งกับ Servo และ MediaPipe ไม่ยุ่งกับ Motor เพื่อความรวดเร็วสูงสุด (Max Performance)

---

### อัลกอริทึม: Independent Pipeline (ทำงานแยกอิสระ)

```
          ┌────────────────────────────────────────┐
 Frame ──→│       Dual AI Parallel Pipeline        │
          │                                        │
          │  ┌─────────────┐   ┌────────────────┐ │
          │  │ AI #1: YOLO │   │ AI #2: MediaPipe│ │
          │  │ (Motor Port)│   │ (Servo Port)   │ │
          │  │             │   │                 │ │
          │  │ Output:     │   │ Output:         │ │
          │  │ Target Speed│   │ Target Angle    │ │
          │  └──────┬──────┘   └──────┬──────────┘ │
          │         │                 │             │
          │         ▼                 ▼             │
          │  ┌────────────────────────────────┐    │
          │  │      Shared State Update       │    │
          │  └──────────────┬─────────────────┘    │
          │                 │                       │
          │                 ▼                       │
          │          Hardware Control               │
          └────────────────────────────────────────┘
```

---

### ตารางสรุปการควบคุม (Project 013)

**🤖 YOLO (ตัวหลัก - ควบคุมความเร็ว Motor):**

| ท่ามือ ASL | ลักษณะท่า | ความเร็ว Motor |
|-----------|----------|---------------|
| **S** | กำปั้น | 0% (หยุด) |
| **O** | วงกลม | 0% (หยุด) |
| **D** | ชู 1 นิ้ว (ชี้) | 30% |
| **X** | งอนิ้วชี้ | 30% |
| **V** | ชู 2 นิ้ว | 60% |
| **W** | ชู 3 นิ้ว | 100% |

**🖐️ MediaPipe (ตัวหลัก - ควบคุมมุม Servo):**

| ท่ามือ | ลักษณะท่า | การทำงาน Servo |
|--------|----------|---------------|
| **Thumb Up** | 👍 ชูหัวแม่มือ | +5° (หมุนขวา) |
| **Pinky Up** | 🤙 ชูนิ้วก้อย | -5° (หมุนซ้าย) |

### โครงสร้างไฟล์

```
Project013/
├── models/
│   └── best.pt           # YOLO model ที่ train เอง
├── config.py             # แยกค่าส่ง YOLO (Motor) และ MP (Servo)
├── camera_module.py      # ทำงาน AI Parallel (YOLO + MP Hands + Face)
├── main.py               # Thread Manager
├── shared_state.py       # รวมพิกัดและสถานะ AI
├── motor_module.py       # ควบคุมพัดลม
├── servo_module.py       # ควบคุมมุมการหมุน
└── requirements.txt      # ultralytics + mediapipe
```

---

## ฮาร์ดแวร์

### อุปกรณ์ที่ใช้

| อุปกรณ์ | รุ่น | หน้าที่ |
|---------|-----|---------|
| **SBC** | Raspberry Pi 5 | ประมวลผลหลัก |
| **Camera** | Pi Camera Module 3 | จับภาพมือ/หน้า |
| **Motor Driver** | TB6612FNG | ควบคุม DC Motor |
| **DC Motor** | — | พัดลม |
| **Servo** | MG996R | หมุนหัวพัดลม |

### การต่อ GPIO

| GPIO Pin | อุปกรณ์ | หน้าที่ |
|----------|---------|---------|
| GPIO 12 (Pin 32) | Motor PWM | ควบคุมความเร็ว |
| GPIO 17 (Pin 11) | Motor AIN1 | ทิศทางหมุน |
| GPIO 27 (Pin 13) | Motor AIN2 | ทิศทางหมุน |
| GPIO 19 (Pin 35) | Servo Signal | ควบคุมมุมหมุน |

---

## วิธีติดตั้งและใช้งาน

### ขั้นที่ 1: ติดตั้ง Dependencies บน Pi 5

```bash
# สำหรับ Project010 (MediaPipe)
pip install gpiozero rpi-lgpio opencv-python mediapipe numpy

# สำหรับ Project011 (YOLO Cloud)
pip install gpiozero rpi-lgpio opencv-python mediapipe inference numpy

# สำหรับ Project012 / 013 (YOLO Local)
pip install gpiozero rpi-lgpio opencv-python mediapipe ultralytics numpy
```

### ขั้นที่ 2: รันโปรเจค

```bash
# เลือก Project ที่ต้องการ
cd Project010   # หรือ Project011, Project012, Project013
python3 main.py
```

### ขั้นที่ 3: ใช้งาน

- ทำท่ามือหน้ากล้อง → Motor/Servo จะตอบสนอง
- เอาหน้าเข้าใกล้ → Motor จะ **หยุดทันที** (Safety)
- กด **'q'** บนหน้าต่างกล้อง → ออกจากโปรแกรม

---

## เปรียบเทียบ AI Algorithms

| เกณฑ์ | MediaPipe (010) | YOLO Cloud (011) | YOLO Local (012) | Dual AI (013) |
|-------|----------------|-------------------|-------------------|---------------|
| **ตรวจจับ** | 21 Landmarks | Cloud Inference | Local Inference | YOLO + Landmarks |
| **นับนิ้ว** | Logic (TIP vs PIP) | Class โดยตรง | Class โดยตรง | **แยกหน้าที่กัน** |
| **ความเร็ว** | เร็วมาก | ช้า (cloud) | เร็ว | **เร็ว (Parallel)** |
| **ความแม่น** | ดี | ดีมาก (98.5%) | ดีมาก (98.3%) | **สูง (เฉพาะทาง)** |
| **Internet** | ไม่ต้อง | ต้อง | ไม่ต้อง | ไม่ต้อง |
| **ความซับซ้อน** | ปานกลาง | ง่าย | ปานกลาง | สูง |
| **Train Model** | ไม่ต้อง | ไม่ต้อง | **ต้อง (เอง)** | **ต้อง (เอง)** |